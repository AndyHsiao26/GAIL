{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as dist\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.set_random_seed(2019)\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(self, sess, obs, acs, hidden_size, name, trainable, init_std=1.0):\n",
    "        self.sess = sess\n",
    "        self.obs = obs\n",
    "        self.acs = acs\n",
    "        self.hidden_size = hidden_size\n",
    "        self.name = name\n",
    "        self.trainable = trainable\n",
    "        self.init_std = init_std\n",
    "\n",
    "        self.num_ac = self.acs.get_shape().as_list()[-1]\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        with tf.variable_scope('critic'):\n",
    "            c_h1 = layers.fully_connected(self.obs, self.hidden_size, trainable=self.trainable)\n",
    "            c_out = layers.fully_connected(c_h1, 1, activation_fn=None, trainable=self.trainable)\n",
    "\n",
    "        with tf.variable_scope('actor'):\n",
    "            a_h1 = layers.fully_connected(self.obs, self.hidden_size, trainable=self.trainable)\n",
    "            a_out = layers.fully_connected(a_h1, self.num_ac, activation_fn=None, trainable=self.trainable)\n",
    "\n",
    "            log_std = tf.get_variable('log_std', [1, self.num_ac], dtype=tf.float32,\n",
    "                                      initializer=tf.constant_initializer(self.init_std),\n",
    "                                      trainable=self.trainable)\n",
    "\n",
    "        std = tf.exp(log_std)\n",
    "        a_dist = dist.Normal(a_out, std)\n",
    "        self.log_prob = a_dist.log_prob(self.acs)\n",
    "        self.entropy = tf.reduce_mean(a_dist.entropy())\n",
    "\n",
    "        self.value = tf.identity(c_out)\n",
    "        self.action = a_dist.sample()\n",
    "\n",
    "    def params(self):\n",
    "        return tf.global_variables(self.name).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Proximal Policy Optimization Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, sess, ob_shape, ac_shape, lr, hidden_size, eps=0.2, v_coeff=0.5, ent_coeff=0.01):\n",
    "        self.sess = sess\n",
    "        self.ob_shape = ob_shape\n",
    "        self.ac_shape = ac_shape\n",
    "        self.lr = lr\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eps = eps\n",
    "        self.v_coeff = v_coeff\n",
    "        self.ent_coeff = ent_coeff\n",
    "\n",
    "        self._create_ppo_graph()\n",
    "\n",
    "    def _create_ppo_graph(self):\n",
    "        self.obs = tf.placeholder(dtype=tf.float32, shape=[None] + self.ob_shape, name='observation')\n",
    "        self.acs = tf.placeholder(dtype=tf.float32, shape=[None] + self.ac_shape, name='action')\n",
    "        self.returns = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "        self.advs = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "\n",
    "        self.pi = ActorCritic(self.sess, self.obs, self.acs, self.hidden_size, 'new_pi', trainable=True)\n",
    "        self.old_pi = ActorCritic(self.sess, self.obs, self.acs, self.hidden_size, 'old_pi', trainable=False)\n",
    "\n",
    "        self.pi_param = self.pi.params()\n",
    "        self.old_pi_param = self.old_pi.params()\n",
    "\n",
    "        with tf.name_scope('update_old_policy'):\n",
    "            self.oldpi_update = [oldp.assign(p) for p, oldp in zip(self.pi_param, self.old_pi_param)]\n",
    "\n",
    "        with tf.name_scope('loss'):\n",
    "            ratio = tf.exp(self.pi.log_prob - self.old_pi.log_prob)\n",
    "            surr = ratio * self.advs\n",
    "            self.actor_loss = tf.reduce_mean(\n",
    "                tf.minimum(surr, tf.clip_by_value(ratio, 1 - self.eps, 1 + self.eps) * self.advs))\n",
    "            self.critic_loss = tf.reduce_mean(tf.square(self.returns - self.pi.value))\n",
    "\n",
    "            self.loss = (- self.actor_loss - self.ent_coeff * tf.reduce_mean(self.pi.entropy)\n",
    "                         + self.v_coeff * self.critic_loss)\n",
    "\n",
    "            with tf.variable_scope('train_op'):\n",
    "                grads = tf.gradients(self.loss, self.pi_param)\n",
    "                self.grads = list(zip(grads, self.pi_param))\n",
    "                self.train_op = tf.train.AdamOptimizer(self.lr).apply_gradients(self.grads)\n",
    "                                                                                #global_step=self.global_step)\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        return self.sess.run(self.pi.action, feed_dict={self.obs: obs})\n",
    "\n",
    "    def get_value(self, obs):\n",
    "        return self.sess.run(self.pi.value, feed_dict={self.obs: obs})\n",
    "\n",
    "    def assign_old_pi(self):\n",
    "        self.sess.run(self.oldpi_update)\n",
    "\n",
    "    def update(self, obs, acs, returns, advs):\n",
    "        feed_dict = {self.obs: obs,\n",
    "                     self.acs: acs,\n",
    "                     self.returns: returns,\n",
    "                     self.advs: advs\n",
    "                     }\n",
    "\n",
    "        self.sess.run(self.train_op, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, obs, acs, returns, advantage):\n",
    "    batch_size = obs.shape[0]\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield (obs[rand_ids, :], acs[rand_ids, :],\n",
    "               returns[rand_ids, :], advantage[rand_ids, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(model, vis=False):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        if vis:\n",
    "            env.render()\n",
    "        ac = model.get_action([ob])[0]\n",
    "        next_ob, reward, done, _ = env.step(ac)\n",
    "        ob = next_ob\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "lr = 3e-4\n",
    "num_steps = 20\n",
    "mini_batch_size = 5\n",
    "ppo_epochs = 4\n",
    "threshold_reward = -200\n",
    "\n",
    "max_frames = 15000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob_shape = list(envs.observation_space.shape)\n",
    "ac_shape = list(envs.action_space.shape)\n",
    "\n",
    "ob = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "ppo = PPO(sess, ob_shape, ac_shape, lr, hidden_size)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    obs = []\n",
    "    acs = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "\n",
    "        ac = ppo.get_action(ob)\n",
    "        next_ob, reward, done, _ = envs.step(ac)\n",
    "\n",
    "        value = ppo.get_value(ob)\n",
    "        values.append(value)\n",
    "        rewards.append(reward[:, np.newaxis])\n",
    "        masks.append((1-done)[:, np.newaxis])\n",
    "\n",
    "        obs.append(ob)\n",
    "        acs.append(ac)\n",
    "\n",
    "        ob = next_ob\n",
    "        frame_idx += 1\n",
    "\n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env(ppo) for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "\n",
    "    next_value = ppo.get_value(next_ob)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns = np.concatenate(returns)\n",
    "    values = np.concatenate(values)\n",
    "    obs = np.concatenate(obs)\n",
    "    acs = np.concatenate(acs)\n",
    "    advantages = returns - values\n",
    "\n",
    "    ppo.assign_old_pi()\n",
    "    for _ in range(ppo_epochs):\n",
    "        for ob_batch, ac_batch, return_batch, adv_batch in ppo_iter(mini_batch_size, obs, acs, returns, advantages):\n",
    "            ppo.update(ob_batch, ac_batch, return_batch, adv_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: -246.7083191744881\n",
      "episode: 1 reward: -253.23816676152242\n",
      "episode: 2 reward: -5.700545703579701\n",
      "episode: 3 reward: -134.0083425356645\n",
      "episode: 4 reward: -4.051806843136793\n",
      "episode: 5 reward: -133.4349354178555\n",
      "episode: 6 reward: -250.64500114689358\n",
      "episode: 7 reward: -134.59654080910602\n",
      "episode: 8 reward: -126.93592056346755\n",
      "episode: 9 reward: -238.48087818961002\n",
      "episode: 10 reward: -125.94405152664496\n",
      "episode: 11 reward: -880.426643291184\n",
      "episode: 12 reward: -984.9207227420158\n",
      "episode: 13 reward: -7.447175281558876\n",
      "episode: 14 reward: -132.81241822739992\n",
      "episode: 15 reward: -334.3019648738332\n",
      "episode: 16 reward: -124.14344277851467\n",
      "episode: 17 reward: -263.15693693385225\n",
      "episode: 18 reward: -125.04894356274893\n",
      "episode: 19 reward: -120.9657711945391\n",
      "episode: 20 reward: -6.138197392554562\n",
      "episode: 21 reward: -128.85976633437514\n",
      "episode: 22 reward: -125.78918452957559\n",
      "episode: 23 reward: -126.30160915478247\n",
      "episode: 24 reward: -248.23915811378657\n",
      "episode: 25 reward: -544.3779985222858\n",
      "episode: 26 reward: -237.37833963067308\n",
      "episode: 27 reward: -263.69815674720786\n",
      "episode: 28 reward: -131.21617620883475\n",
      "episode: 29 reward: -136.62162876539224\n",
      "episode: 30 reward: -341.0952713153558\n",
      "episode: 31 reward: -237.51887533884184\n",
      "episode: 32 reward: -783.1373773289915\n",
      "episode: 33 reward: -353.1005258094403\n",
      "episode: 34 reward: -132.51477134947467\n",
      "episode: 35 reward: -132.14864831651855\n",
      "episode: 36 reward: -132.0642871406227\n",
      "episode: 37 reward: -138.27200475298375\n",
      "episode: 38 reward: -269.6715052601267\n",
      "episode: 39 reward: -117.15845828700623\n",
      "episode: 40 reward: -126.6085425216721\n",
      "episode: 41 reward: -123.96870931197896\n",
      "episode: 42 reward: -136.09022207358203\n",
      "episode: 43 reward: -133.5957015112119\n",
      "episode: 44 reward: -253.52016445190696\n",
      "episode: 45 reward: -299.4328687094707\n",
      "episode: 46 reward: -129.39132532086037\n",
      "episode: 47 reward: -11.392404854119032\n",
      "episode: 48 reward: -130.7617859095362\n",
      "episode: 49 reward: -135.75781091953817\n",
      "episode: 50 reward: -7.028184393916958\n",
      "episode: 51 reward: -497.120589306835\n",
      "episode: 52 reward: -136.3961266512794\n",
      "episode: 53 reward: -134.44399172484384\n",
      "episode: 54 reward: -361.7007600051424\n",
      "episode: 55 reward: -510.7313155674219\n",
      "episode: 56 reward: -3.5458460663311695\n",
      "episode: 57 reward: -256.87520794688857\n",
      "episode: 58 reward: -5.514971095942757\n",
      "episode: 59 reward: -902.1307859279964\n",
      "episode: 60 reward: -785.7002470350495\n",
      "episode: 61 reward: -130.18709912808217\n",
      "episode: 62 reward: -249.1711859830412\n",
      "episode: 63 reward: -133.73059694774543\n",
      "episode: 64 reward: -248.4604621842748\n",
      "episode: 65 reward: -127.61079162977391\n",
      "episode: 66 reward: -351.09230478227767\n",
      "episode: 67 reward: -129.85225377223395\n",
      "episode: 68 reward: -364.3984824902885\n",
      "episode: 69 reward: -118.63440224533836\n",
      "episode: 70 reward: -132.23391181583236\n",
      "episode: 71 reward: -255.3124041290767\n",
      "episode: 72 reward: -915.1205178379574\n",
      "episode: 73 reward: -915.9678529486478\n",
      "episode: 74 reward: -131.00869730634787\n",
      "episode: 75 reward: -827.6691929147742\n",
      "episode: 76 reward: -234.1831100559387\n",
      "episode: 77 reward: -256.97715782013205\n",
      "episode: 78 reward: -523.9933595179266\n",
      "episode: 79 reward: -242.8996749325203\n",
      "episode: 80 reward: -131.08684228226818\n",
      "episode: 81 reward: -254.55019867661593\n",
      "episode: 82 reward: -123.72790654599494\n",
      "episode: 83 reward: -265.49470402874516\n",
      "episode: 84 reward: -136.0608593379006\n",
      "episode: 85 reward: -256.31620094603926\n",
      "episode: 86 reward: -134.17933051756708\n",
      "episode: 87 reward: -131.68878228475035\n",
      "episode: 88 reward: -415.9040120536897\n",
      "episode: 89 reward: -132.854016502436\n",
      "episode: 90 reward: -246.93535703371774\n",
      "episode: 91 reward: -930.1309807482867\n",
      "episode: 92 reward: -4.5563863262111495\n",
      "episode: 93 reward: -245.84583822052753\n",
      "episode: 94 reward: -4.127292589750983\n",
      "episode: 95 reward: -129.96562048170168\n",
      "episode: 96 reward: -133.01395791229535\n",
      "episode: 97 reward: -520.8819178384429\n",
      "episode: 98 reward: -135.89040676452288\n",
      "episode: 99 reward: -242.55814399759362\n",
      "episode: 100 reward: -132.23079051309705\n",
      "episode: 101 reward: -251.93303422938047\n",
      "episode: 102 reward: -129.54811126984782\n",
      "episode: 103 reward: -2.6961816819114306\n",
      "episode: 104 reward: -135.01903013207186\n",
      "episode: 105 reward: -121.480417874189\n",
      "episode: 106 reward: -7.342198044776332\n",
      "episode: 107 reward: -132.07650222640297\n",
      "episode: 108 reward: -245.44438201992804\n",
      "episode: 109 reward: -126.75447086421885\n",
      "episode: 110 reward: -126.18843398805828\n",
      "episode: 111 reward: -4.405324695021443\n",
      "episode: 112 reward: -353.895328561455\n",
      "episode: 113 reward: -139.17560101644733\n",
      "episode: 114 reward: -373.3853309295317\n",
      "episode: 115 reward: -240.68804923107913\n",
      "episode: 116 reward: -548.5053731659931\n",
      "episode: 117 reward: -133.95946339625294\n",
      "episode: 118 reward: -804.1236717357637\n",
      "episode: 119 reward: -136.15940174147624\n",
      "episode: 120 reward: -120.17086226973014\n",
      "episode: 121 reward: -133.4119921896871\n",
      "episode: 122 reward: -118.08381599569445\n",
      "episode: 123 reward: -864.9121461261483\n",
      "episode: 124 reward: -257.104558730817\n",
      "episode: 125 reward: -118.4621049265241\n",
      "episode: 126 reward: -132.7880142607249\n",
      "episode: 127 reward: -136.36550811218373\n",
      "episode: 128 reward: -122.9192008594819\n",
      "episode: 129 reward: -5.991878043358962\n",
      "episode: 130 reward: -685.635851392719\n",
      "episode: 131 reward: -256.30889242889526\n",
      "episode: 132 reward: -129.83840246691244\n",
      "episode: 133 reward: -255.1354021345459\n",
      "episode: 134 reward: -139.7111964947442\n",
      "episode: 135 reward: -373.37285268928616\n",
      "episode: 136 reward: -138.10125334631783\n",
      "episode: 137 reward: -133.68615237805048\n",
      "episode: 138 reward: -135.46261642640604\n",
      "episode: 139 reward: -134.03632652937836\n",
      "episode: 140 reward: -9.354071640357166\n",
      "episode: 141 reward: -136.7170845451801\n",
      "episode: 142 reward: -120.12717708631665\n",
      "episode: 143 reward: -258.9153129360778\n",
      "episode: 144 reward: -7.072425630745299\n",
      "episode: 145 reward: -132.19041155078708\n",
      "episode: 146 reward: -811.6096352939842\n",
      "episode: 147 reward: -373.06393314701074\n",
      "episode: 148 reward: -363.38394877448724\n",
      "episode: 149 reward: -123.9955941089184\n",
      "episode: 150 reward: -527.7258675806444\n",
      "episode: 151 reward: -242.2570656343642\n",
      "episode: 152 reward: -134.65587793550952\n",
      "episode: 153 reward: -128.39559714375352\n",
      "episode: 154 reward: -249.223159970458\n",
      "episode: 155 reward: -231.34896342417392\n",
      "episode: 156 reward: -131.1408479877561\n",
      "episode: 157 reward: -236.74199642718182\n",
      "episode: 158 reward: -948.5021744969807\n",
      "episode: 159 reward: -132.83957415682121\n",
      "episode: 160 reward: -524.5370933572593\n",
      "episode: 161 reward: -243.0287142598327\n",
      "episode: 162 reward: -122.71305927200633\n",
      "episode: 163 reward: -126.18943620170492\n",
      "episode: 164 reward: -129.95336462608907\n",
      "episode: 165 reward: -134.85292118033243\n",
      "episode: 166 reward: -130.51391429044781\n",
      "episode: 167 reward: -135.5240389914409\n",
      "episode: 168 reward: -136.18151421611964\n",
      "episode: 169 reward: -5.8204491504808455\n",
      "episode: 170 reward: -134.30811072998404\n",
      "episode: 171 reward: -10.076686581356256\n",
      "episode: 172 reward: -117.38736926301094\n",
      "episode: 173 reward: -251.65264647400997\n",
      "episode: 174 reward: -247.00953316566486\n",
      "episode: 175 reward: -128.11329710238564\n",
      "episode: 176 reward: -229.7113673727123\n",
      "episode: 177 reward: -237.47129946770485\n",
      "episode: 178 reward: -257.11877859775603\n",
      "episode: 179 reward: -247.52349113932019\n",
      "episode: 180 reward: -780.5933891230478\n",
      "episode: 181 reward: -134.99202432101885\n",
      "episode: 182 reward: -123.07528799116363\n",
      "episode: 183 reward: -244.74907876863568\n",
      "episode: 184 reward: -382.8983411159221\n",
      "episode: 185 reward: -244.59884545341325\n",
      "episode: 186 reward: -234.95193353437833\n",
      "episode: 187 reward: -4.734196388017763\n",
      "episode: 188 reward: -139.23908164231023\n",
      "episode: 189 reward: -478.0602720022608\n",
      "episode: 190 reward: -236.48318167348276\n",
      "episode: 191 reward: -5.578997180857555\n",
      "episode: 192 reward: -336.9786685938948\n",
      "episode: 193 reward: -258.3918890522727\n",
      "episode: 194 reward: -124.98065496947197\n",
      "episode: 195 reward: -119.87170624966163\n",
      "episode: 196 reward: -133.94109306262214\n",
      "episode: 197 reward: -125.35210946803613\n",
      "episode: 198 reward: -136.3684201835076\n",
      "episode: 199 reward: -130.5198291684345\n",
      "episode: 200 reward: -135.3601062733349\n",
      "episode: 201 reward: -127.21632338837439\n",
      "episode: 202 reward: -132.4365313894933\n",
      "episode: 203 reward: -135.87867957964306\n",
      "episode: 204 reward: -131.7071478108248\n",
      "episode: 205 reward: -132.32958077695216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 206 reward: -133.52333417951223\n",
      "episode: 207 reward: -243.62450424597014\n",
      "episode: 208 reward: -812.8932264116117\n",
      "episode: 209 reward: -260.25572847178313\n",
      "episode: 210 reward: -252.28624118390204\n",
      "episode: 211 reward: -256.56818442632067\n",
      "episode: 212 reward: -128.46027802369517\n",
      "episode: 213 reward: -251.81459387927669\n",
      "episode: 214 reward: -922.0632165454687\n",
      "episode: 215 reward: -122.0069462289584\n",
      "episode: 216 reward: -1004.672806562921\n",
      "episode: 217 reward: -502.00425963406366\n",
      "episode: 218 reward: -126.08372662380091\n",
      "episode: 219 reward: -772.0184865523722\n",
      "episode: 220 reward: -9.137315250927196\n",
      "episode: 221 reward: -132.0065599677143\n",
      "episode: 222 reward: -132.6284647300157\n",
      "episode: 223 reward: -132.86464925551684\n",
      "episode: 224 reward: -118.67478773728922\n",
      "episode: 225 reward: -528.6739027053379\n",
      "episode: 226 reward: -523.0993566717337\n",
      "episode: 227 reward: -278.3725787859839\n",
      "episode: 228 reward: -135.4623819659236\n",
      "episode: 229 reward: -131.15073386559516\n",
      "episode: 230 reward: -3.76757564454908\n",
      "episode: 231 reward: -250.9167911738178\n",
      "episode: 232 reward: -122.71297127505831\n",
      "episode: 233 reward: -264.6820693313714\n",
      "episode: 234 reward: -6.5000947230497745\n",
      "episode: 235 reward: -7.456440449990433\n",
      "episode: 236 reward: -127.7294630454604\n",
      "episode: 237 reward: -4.82405982010701\n",
      "episode: 238 reward: -129.02384866359185\n",
      "episode: 239 reward: -788.9280219050175\n",
      "episode: 240 reward: -250.15244601198813\n",
      "episode: 241 reward: -270.96252523530785\n",
      "episode: 242 reward: -815.5688236551679\n",
      "episode: 243 reward: -250.19917672978903\n",
      "episode: 244 reward: -244.76188647525274\n",
      "episode: 245 reward: -381.2049087637684\n",
      "episode: 246 reward: -135.011868072807\n",
      "episode: 247 reward: -133.14182749896028\n",
      "episode: 248 reward: -138.0872398448006\n",
      "episode: 249 reward: -262.25046926289974\n",
      "\n",
      "(50000, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        ac = ppo.get_action([ob])[0]\n",
    "        next_ob, reward, done, _ = env.step(ac)\n",
    "        ob = next_ob\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([ob, ac]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
